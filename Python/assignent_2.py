# -*- coding: utf-8 -*-
"""Assignent 2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pe2zbPgJuTPFRPb9HUY2VemNaqiZooQt
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd

import scipy
import matplotlib.pyplot as plt
from pylab import rcParams
import urllib
import sklearn
from sklearn.neighbors import KNeighborsClassifier
from sklearn import neighbors
from sklearn import preprocessing
from sklearn.model_selection import train_test_split
from sklearn.metrics import f1_score, accuracy_score, roc_auc_score, plot_roc_curve, classification_report, confusion_matrix
from sklearn.preprocessing import StandardScaler
from sklearn import metrics
np.set_printoptions(precision=4, suppress= 1)
# %matplotlib inline
rcParams['figure.figsize'] = 7,4
plt.style.use('seaborn-whitegrid')

"""Load Data"""

address = '/content/drive/MyDrive/a2/train.csv'

dftrain = pd.read_csv(address)
dftest = pd.read_csv("/content/drive/MyDrive/a2/test.csv")
dftrain.drop("id", axis = 1, inplace = True)
dfid = pd.DataFrame({'id':dftest['id']})


dftrain

dftest

"""Find missing values"""

dftrain.isna().sum().sum()

"""Thankfully, there are no missing values.

Find Outliers
"""

dftrain.loc[:, dftrain.columns[dftrain.max()<=1].to_list()].boxplot(figsize=(20,10), rot = 90);

dftrain.loc[:, dftrain.columns[dftrain.max()>1].to_list()].boxplot(figsize=(20,10), rot = 90);

"""Outlier Handling"""

dftrain.columns

#for column in dftrain.columns:
 # q1 = dftrain[column].quantile(.25)
  #q3 = dftrain[column].quantile(.75)
  #iqr = q3 - q1
  #lower = q1 - 1.5*iqr
  #upper = q3 + 1.5*iqr
  #median = dftrain[column].sum()/len(dftrain[column])
  #print(column)
  #for row in column:
  #  if (dftrain > upper) or (lower < dftrain[row]):
  #    dftrain[row] = median

dftrain.loc[:, dftrain.columns[dftrain.max()<=1].to_list()].boxplot(figsize=(20,10), rot = 90);

dftrain.loc[:, dftrain.columns[dftrain.max()>1].to_list()].boxplot(figsize=(20,10), rot = 90);

"""Feature Scaling - Standardization chosen bc knn models have greater benefit from this type of scaler"""

scaler = StandardScaler()
scaler.fit(dftrain.drop('quality', axis = 1))
Scaled_array = scaler.transform(dftrain.drop('quality', axis = 1))
xScaled = pd.DataFrame(Scaled_array, columns = dftrain.drop('quality', axis = 1).columns)

"""Data splitting"""

x = xScaled
y = dftrain['quality']
#x = dftrain.drop(columns="quality", axis = 1)
#y = dftrain["quality"]

x_train, x_test, y_train, y_test= train_test_split(x, y, test_size = .25)
x_train = scaler.fit_transform(x_train)
x_test = scaler.transform(x_test)

x_test.shape

x_train.shape

y_test.shape

y_train.shape

dftest.drop(columns="id", inplace=True)
dftest.shape

"""Model"""

knn = KNeighborsClassifier(n_neighbors = 5)
knn.fit(x_train, y_train)
solution = knn.predict(dftest)
len(solution)

"""Accuracy"""

#print("F1: ", f1_score(y_test, solution))

#print(roc_auc_score(y_test, knn.predict_proba(x_test)))

"""Output to CSV"""

output = pd.DataFrame({"quality":solution})
output.to_csv("a2sol.csv")
output